# -*- coding: utf-8 -*-
"""0424.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rga48qQsAiHdKmdUBaOxn3vbblWQfEht
"""

import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from shapely.geometry import box
from shapely.geometry import Point
from shapely.ops import unary_union
from matplotlib.patches import Patch
import numpy as np

########################################
# 0) Shapefile 로드 & 'Sector'를 int로 통일
########################################
shapefile_path = "Balanced_Beats_V2.shp"
berkeley_beats = gpd.read_file(shapefile_path).to_crs(epsg=4326)

# 🔥 만약 shapefile의 'Sector'가 문자열이면, 아래 코드로 int 변환
berkeley_beats["Sector"] = berkeley_beats["Sector"].astype(int)

########################################
# 1) Grid 생성 & sjoin으로 Sector 할당
########################################
minx, miny, maxx, maxy = berkeley_beats.total_bounds
cell_size = 0.001  # 100m 격자

grid_cells = []
x = minx
while x < maxx:
    y = miny
    while y < maxy:
        cell = box(x, y, x + cell_size, y + cell_size)
        grid_cells.append(cell)
        y += cell_size
    x += cell_size

grid = gpd.GeoDataFrame(geometry=grid_cells, crs=berkeley_beats.crs)

# Centroid 계산 & Spatial Join
grid["centroid"] = grid.geometry.centroid
centroids = grid.copy()
centroids["geometry"] = centroids["centroid"]

centroids_sjoined = gpd.sjoin(
    centroids,
    berkeley_beats,
    how="left",
    predicate="intersects"
).reset_index(drop=True)

grid["Sector"] = centroids_sjoined["Sector"]

# 결측 제거 & Grid_ID 부여
grid = grid.dropna(subset=["Sector"])
grid["Sector"] = grid["Sector"].astype(int)  # 🔥 정수 변환 (통일)
grid["Grid_ID"] = grid.index

########################################
# 2) 기본 시각화 (Sector별 Grid)
########################################
fig, ax = plt.subplots(figsize=(12,8))
unique_sectors = sorted(grid["Sector"].unique())
cmap = plt.cm.get_cmap("tab20", len(unique_sectors))
color_dict = {sec: cmap(i) for i, sec in enumerate(unique_sectors)}

for sec in unique_sectors:
    subset = grid[grid["Sector"] == sec]
    subset.plot(ax=ax, facecolor=color_dict[sec], edgecolor="black", linewidth=0.5, alpha=1.0)

legend_patches = [
    Patch(facecolor=color_dict[sec], edgecolor="black", label=f"Sector {sec}")
    for sec in unique_sectors
]
ax.legend(
    handles=legend_patches,
    title="Centroid-Based Sector Assignment",
    loc="upper left",
    bbox_to_anchor=(1.05, 1),
    borderaxespad=0.
)

ax.set_title("Grid-Based Patrol Sector Assignment")
ax.set_axis_off()
plt.show()

########################################
# 3) Boundary Grid 식별
########################################
boundary_grids = grid.copy()
boundary_grids["is_boundary"] = False

for idx, row in grid.iterrows():
    neighbors = grid[grid.geometry.touches(row.geometry)]
    if not neighbors.empty:
        if any(neighbors["Sector"] != row["Sector"]):
            boundary_grids.at[idx, "is_boundary"] = True

# boundary_grids_info: 경계인 것만
boundary_grids_info = boundary_grids[boundary_grids["is_boundary"]].copy()

# 🔥 int형 Sector 유지
boundary_grids_info["Sector"] = boundary_grids_info["Sector"].astype(int)

# load year data
import pandas as pd
df = pd.read_csv("2024.csv")

# ✅ Count duplicate (lat, lon) rows
duplicate_coords = df.duplicated(subset=['lat', 'lon'], keep=False).sum()

# ✅ Total number of rows
total_rows = len(df)

# ✅ Calculate duplicate percentage
duplicate_ratio = (duplicate_coords / total_rows) * 100

# ✅ Print results
print(f"Number of rows with duplicate (lat, lon) coordinates: {duplicate_coords}")
print(f"Percentage of duplicate rows in the dataset: {duplicate_ratio:.2f}%")

unique_coords = df[['lat', 'lon']].drop_duplicates()
print(f"Unique (lat, lon) pairs: {len(unique_coords)}")

# ✅ Count occurrences of each (lat, lon) pair
coord_counts = df.groupby(['lat', 'lon']).size().reset_index(name='count')

# ✅ Sort by most frequent duplicates
coord_counts = coord_counts.sort_values(by='count', ascending=False)

# ✅ Select top 10
top_10_coords = coord_counts.head(10)

# ✅ Display the result
print(top_10_coords)

df = df[~((df['lat'] == 37.87053067971685) & (df['lon'] == -122.273288))]
df.shape

import pandas as pd
import numpy as np
import re
from sklearn.preprocessing import MinMaxScaler

# 2️⃣ **필요한 컬럼 선택 및 복사본 생성**
selected_columns = ['Priority', 'lat', 'lon', 'Time Spent Responding', 'Dispositions']
new_df = df[selected_columns].copy()  # 🚨 복사본 생성

# 4️⃣ **IQR 이상치 값을 0으로 변경하는 함수**
def replace_outliers_with_zero(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # 이상치인 경우 0으로 설정
    df[column] = df[column].apply(lambda x: 0 if x < lower_bound or x > upper_bound else x)
    return df

# ✅ **이상치 값을 0으로 변경 적용**
new_df = replace_outliers_with_zero(new_df, 'Time Spent Responding')

# 5️⃣ **Priority 숫자 변환 함수**
def extract_priority(level):
    if pd.isna(level) or level.strip() == "":
        return 0
    match = re.search(r'(\d+)', level)
    if match:
        priority = match.group(1)
        return 1 if priority == "1F" else int(priority)
    return 0

# ✅ **Priority 숫자 변환 후 컬럼 추가**
new_df['Priority Numeric'] = new_df['Priority'].apply(extract_priority)

# 6️⃣ **Priority Weight 매핑**
priority_weights = {1: 1.0, 2: 0.7, 3: 0.4, 4: 0.2, 5: 0.1}
new_df['Priority Weight'] = new_df['Priority Numeric'].apply(lambda x: priority_weights.get(x, 0.0))

# 7️⃣ **Min-Max Scaling 적용**
scaler = MinMaxScaler()
new_df['Scaled Response Time'] = scaler.fit_transform(new_df[['Time Spent Responding']])

# 8️⃣ **Dispositions 가중치 적용**
def get_disposition_weight(disposition):
    if pd.isna(disposition) or disposition.strip() == "":
        return 0.3
    disposition = disposition.lower()
    if "arrest" in disposition:
        return 1.0
    elif "case" in disposition:
        return 0.7
    else:
        return 0.3

# ✅ **Disposition Weight 컬럼 추가**
new_df['Disposition Weight'] = new_df['Dispositions'].apply(get_disposition_weight)

# 1️⃣ NPPS 점수 계산 (각 가중치는 조정 가능)
new_df["NPPS"] = (0.7 * new_df["Priority Weight"]) + (0.1 * new_df["Scaled Response Time"]) + (0.2 * new_df["Disposition Weight"])

#
total_npps = new_df['NPPS'].sum()
print("Total_NPPS(SUM)", total_npps)

# NPPS 값의 통계 요약
npps_min = new_df["NPPS"].min()
npps_max = new_df["NPPS"].max()
npps_mean = new_df["NPPS"].mean()

# 결과 출력
print(f"Minimum NPPS: {npps_min:.4f}")
print(f"Maximum NPPS: {npps_max:.4f}")
print(f"Average NPPS: {npps_mean:.4f}")


# 결과 확인
new_df.head()

npps_data = new_df.copy()

# 1️⃣ npps_data 불러오기 (서비스 콜 좌표 및 NPPS 값 포함)
npps_data = gpd.GeoDataFrame(npps_data, geometry=gpd.points_from_xy(npps_data['lon'], npps_data['lat']), crs="EPSG:4326")

# 2️⃣ "nearest" 방식으로 서비스 콜을 가장 가까운 Grid에 할당
npps_data = gpd.sjoin_nearest(npps_data, grid, how="left", distance_col="distance_to_grid")

# 3️⃣ Grid별 NPPS 합계 계산
grid_npps_sum = npps_data.groupby("Grid_ID")["NPPS"].sum().reset_index()
grid_npps_sum.rename(columns={"NPPS": "total_npps"}, inplace=True)  # 컬럼명 변경

# 4️⃣ Grid 데이터와 NPPS 값을 병합하여 시각화 준비
grid = grid.merge(grid_npps_sum, on="Grid_ID", how="left")

# 5️⃣ NPPS 값이 NaN인 경우 0으로 채우기 (서비스 콜이 없는 Grid 때문)
grid["total_npps"] = grid["total_npps"].fillna(0)

########################################
# 5) NPPS Heatmap 시각화 (Grid 단위)
########################################

# 6️⃣ Heatmap 시각화
fig, ax = plt.subplots(figsize=(12,8))

# Normalize NPPS 값 (색상 강도 조절)
cmap = plt.cm.get_cmap("Reds")  # 빨간색 계열로 heatmap
norm = plt.Normalize(grid["total_npps"].min(), grid["total_npps"].max())

# Grid 기반 Heatmap 그리기
grid.plot(column="total_npps", cmap=cmap, norm=norm, linewidth=0.5, edgecolor="black", alpha=0.8, ax=ax)

# 컬러바 추가
sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])
cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)
cbar.set_label("Total WLS per Grid", fontsize=12)

# 제목 및 설정
ax.set_title("Aggregated WLS Scores by Grid Cell", fontsize=14)
ax.set_axis_off()  # 축 제거
plt.show()

########################################
# 6) Sector별 NPPS 합계 & 시각화 (Polygon 단위)
########################################
sector_npps_sum = grid.groupby("Sector")["total_npps"].sum().reset_index()
sector_npps_sum.rename(columns={"total_npps": "sector_total_npps"}, inplace=True)

# berkeley_beats와 merge (둘 다 int형 Sector)
berkeley_beats = berkeley_beats.merge(sector_npps_sum, on="Sector", how="left")

print("\n📊 **Sector별 NPPS 총합** 📊\n")
print(berkeley_beats[["Sector", "sector_total_npps"]])

fig, ax = plt.subplots(figsize=(12, 8))
cmap = plt.cm.Reds
norm = mcolors.Normalize(vmin=berkeley_beats["sector_total_npps"].min(),
                         vmax=berkeley_beats["sector_total_npps"].max())

berkeley_beats.plot(column="sector_total_npps", cmap=cmap, norm=norm,
                    edgecolor="black", linewidth=1, alpha=0.8, ax=ax)

# Sector 중심점 라벨 표시
berkeley_beats["centroid"] = berkeley_beats.geometry.centroid
for idx, row in berkeley_beats.iterrows():
    ax.text(row["centroid"].x, row["centroid"].y,
            f"{int(row['Sector'])}",
            fontsize=10, color="black", ha="center", va="center", fontweight="bold")

sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])
cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)
cbar.set_label("Total WLS per Sector", fontsize=12)

ax.set_title("Sector-Level WLS Heatmap in Berkeley Police Patrol", fontsize=14)
ax.set_axis_off()
plt.show()

# 1️⃣ NPPS 점수가 가장 높은 Top 10 Grid 찾기
top_10_hotspots = grid.nlargest(10, "total_npps")[["Grid_ID", "total_npps", "geometry", "Sector"]]

# 2️⃣ Top 10 핫스팟의 중심 좌표 계산 (각 Grid의 중심점)
top_10_hotspots["centroid"] = top_10_hotspots.geometry.centroid

# 3️⃣ 📌 Top 10 핫스팟 Grid 정보 출력
print(" **Top 10 NPPS Hotspot Grids** ")
print(top_10_hotspots[["Grid_ID", "total_npps", "Sector"]])

# 5️⃣ 🔥 Sector-Level NPPS Heatmap + 🏆 Top 10 Hotspot Overlay
fig, ax = plt.subplots(figsize=(12, 8))

# 💡 히트맵 색상 조정 (붉은색 농도 강조)
cmap = plt.cm.Reds
norm = mcolors.Normalize(vmin=berkeley_beats["sector_total_npps"].min(), vmax=berkeley_beats["sector_total_npps"].max())

# 🗺️ **Sector별 NPPS 시각화**
berkeley_beats.plot(column="sector_total_npps", cmap=cmap, norm=norm, edgecolor="black", linewidth=1, alpha=0.8, ax=ax)

# Sector 중심점 라벨 표시
berkeley_beats["centroid"] = berkeley_beats.geometry.centroid
for idx, row in berkeley_beats.iterrows():
    ax.text(row["centroid"].x, row["centroid"].y,
            f"{int(row['Sector'])}",
            fontsize=10, color="black", ha="center", va="center", fontweight="bold")

# 🔥 **Top 10 Hotspot Grid 중심 좌표 추가 (빨간 원)**
top_10_hotspots["centroid"].plot(ax=ax, color="red", markersize=100, marker="o", label="Top 10 WLS Hotspots")

# 컬러바 추가
sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])
cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)
cbar.set_label("Total WLS per Sector", fontsize=12)

# 범례 추가
ax.legend()
ax.set_title(" Sector-Level WLS Heatmap with Top 10 Hotspots", fontsize=14)
ax.set_axis_off()  # 축 제거
plt.show()

########################################
# 7) Excess/Deficient 판단
########################################
sector_npps_sum["Sector"] = sector_npps_sum["Sector"].astype(int)  # 이미 int지만 혹시 모름
sector_npps_sum = sector_npps_sum.sort_values("Sector").reset_index(drop=True)

print("\n📊 **Total NPPS per Sector (Sorted)** 📊\n")
print(sector_npps_sum)

sector_npps_mean = sector_npps_sum["sector_total_npps"].mean()
print(f"\n📊 **Average NPPS Across 14 Sectors: {sector_npps_mean:.2f}** 📊\n")

threshold_high = sector_npps_mean * 1.2
threshold_low  = sector_npps_mean * 0.8

sector_npps_sum["npps_difference(%)"] = ((sector_npps_sum["sector_total_npps"] - sector_npps_mean)
                                         / sector_npps_mean) * 100

excess_npps = sector_npps_sum[sector_npps_sum["sector_total_npps"] > threshold_high]
deficient_npps = sector_npps_sum[sector_npps_sum["sector_total_npps"] < threshold_low]

print("\n🔥 **Excess NPPS Sectors (Above +20%)** 🔥")
print(excess_npps.to_string(index=False))

print("\n🔵 **Deficient NPPS Sectors (Below -20%)** 🔵")
print(deficient_npps.to_string(index=False))

########################################
# 8) boundary_grids_info & sector_npps_sum 병합
########################################
# boundary_grids_info: 경계 Grid만 모아둔 DF
# 'Sector'도 이미 int 상태

boundary_grids_info["Sector"] = boundary_grids_info["Sector"].astype(int)
boundary_grids_info = boundary_grids_info.merge(
    sector_npps_sum[["Sector", "sector_total_npps"]],
    on="Sector",
    how="left"
)

boundary_grids_info.rename(columns={
    "total_npps": "grid_npps",
    "sector_total_npps": "sector_npps"
}, inplace=True)

print("\n🔎 **Boundary Grids Info** 🔎\n")
print(boundary_grids_info.head(10))

########################################
# 9) 경계 Grid 시각화
########################################
fig, ax = plt.subplots(figsize=(12,8))
grid.plot(ax=ax, facecolor="lightgrey", edgecolor="black", linewidth=0.2, alpha=0.6)

boundary_grids_info.plot(ax=ax, facecolor="red", edgecolor="black",
                         linewidth=0.5, alpha=1.0, label="Boundary Grids")

berkeley_beats.boundary.plot(ax=ax, color="black", linewidth=1.5, linestyle="--",
                             label="Sector Boundaries")

ax.legend()
ax.set_title("Patrol Sector Grid with Boundary Highlights", fontsize=14)
ax.set_axis_off()
plt.show()

########################################
# 10) Sector별로 다른 색깔로 경계 Grid 시각화
########################################
fig, ax = plt.subplots(figsize=(12, 8))
grid.plot(ax=ax, facecolor="lightgrey", edgecolor="black", linewidth=0.2, alpha=0.6)

unique_sectors_bdry = boundary_grids_info["Sector"].unique()
cmap2 = plt.cm.get_cmap("tab20", len(unique_sectors_bdry))
color_dict2 = {sec: cmap2(i) for i, sec in enumerate(unique_sectors_bdry)}

for sec in unique_sectors_bdry:
    subset = boundary_grids_info[boundary_grids_info["Sector"] == sec]
    subset.plot(ax=ax, facecolor=color_dict2[sec], edgecolor="black", linewidth=0.5, alpha=1.0, label=f"Sector {sec}")

berkeley_beats.boundary.plot(ax=ax, color="black", linewidth=1.5, linestyle="--", label="Sector Boundaries")

legend_patches2 = [
    Patch(facecolor=color_dict2[sec], edgecolor="black", label=f"Sector {sec}")
    for sec in unique_sectors_bdry
]
sector_boundary_patch = Patch(facecolor="none", edgecolor="black", label="Sector Boundaries", linestyle="--")
legend_patches2.append(sector_boundary_patch)

ax.legend(handles=legend_patches2, title="Boundary Grids by Sector", loc="upper left",
          bbox_to_anchor=(1.05, 1), borderaxespad=0.)
ax.set_title("Multi-Colored Boundary Grids with Sector Silhouette", fontsize=14)
ax.set_axis_off()
plt.show()

########################################
# 11) sector_neighbors (Dictionary)
########################################
sector_neighbors = {
    1: [2],
    2: [1, 3, 4, 14],
    3: [2, 4, 5, 11, 12, 14],
    4: [2, 3, 5, 6],
    5: [3, 4, 6, 9, 10, 11],
    6: [4, 5, 7, 8, 9],
    7: [6, 8],
    8: [6, 7, 9],
    9: [5, 6, 8, 10],
    10: [5, 9, 11],
    11: [3, 5, 10, 12],
    12: [3, 11, 13],
    13: [12, 14],
    14: [2, 3, 13]
}

print("\n**Done!** Everything should be consistent with int-type Sectors.\n")

print("=== Before merge ===")
print(sector_npps_sum)

berkeley_beats = berkeley_beats.merge(sector_npps_sum, on="Sector", how="left")

print("=== After merge ===")
print(sector_npps_sum)  # 다시 출력

import geopandas as gpd
import pandas as pd

# -------------------------------
# 1. Boundary Pairs Info 생성 함수
# -------------------------------
def build_boundary_pairs_info(grid: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """
    grid 내에서 서로 다른 Sector에 속한 Grid끼리 인접(맞닿아 있는)한 경우를 찾아,
    해당 Grid와 맞닿은 이웃 Sector 정보를 포함하는 DataFrame을 반환.
    반환 컬럼: Grid_ID, Sector (현재), neighbor_sector, geometry
    """
    boundary_list = []
    for idx, row in grid.iterrows():
        from_sector = row["Sector"]
        # 해당 Grid와 인접한 모든 Grid 찾기
        neighbors = grid[grid.geometry.touches(row.geometry)]
        # 인접한 Grid 중, Sector가 다른 경우만 선택
        diff_sector_neighbors = neighbors[neighbors["Sector"] != from_sector]
        for n_idx, n_row in diff_sector_neighbors.iterrows():
            boundary_list.append({
                "Grid_ID": row["Grid_ID"],
                "Sector": from_sector,
                "neighbor_sector": n_row["Sector"],
                "geometry": row["geometry"]
            })
    # 리스트를 GeoDataFrame으로 변환
    boundary_pairs_info = gpd.GeoDataFrame(boundary_list, crs=grid.crs)
    # 중복 제거
    boundary_pairs_info.drop_duplicates(subset=["Grid_ID", "Sector", "neighbor_sector"], inplace=True)
    return boundary_pairs_info

# -------------------------------
# 2. Sector별 NPPS 재계산 함수
# -------------------------------
def recalc_sector_npps_sum(grid: gpd.GeoDataFrame) -> pd.DataFrame:
    """
    grid를 기준으로 Sector별 NPPS 합계를 계산하여 DataFrame으로 반환.
    반환 컬럼: Sector, sector_total_npps
    """
    new_sum = grid.groupby("Sector")["total_npps"].sum().reset_index()
    new_sum.rename(columns={"total_npps": "sector_total_npps"}, inplace=True)
    return new_sum

# -------------------------------
# 3. NPPS 변화 출력 함수
# -------------------------------
def print_npps_diff(old_sum: pd.DataFrame, new_sum: pd.DataFrame, sector_list: list):
    """
    old_sum과 new_sum을 merge하여, 지정한 sector_list에 해당하는 Sector들의 NPPS 변화(차이)를 출력.
    """
    merged = old_sum.merge(new_sum, on="Sector", suffixes=("_old", "_new"))
    merged["npps_diff"] = merged["sector_total_npps_new"] - merged["sector_total_npps_old"]
    filtered = merged[merged["Sector"].isin(sector_list)]
    print(filtered[["Sector", "sector_total_npps_old", "sector_total_npps_new", "npps_diff"]])

# -------------------------------
# 4. Boundary 이동 함수 (Bulk 이동)
# -------------------------------
def take_boundary_from_neighbor(grid: gpd.GeoDataFrame, boundary_pairs_info: gpd.GeoDataFrame,
                                  from_sector: int, to_sector: int) -> tuple[gpd.GeoDataFrame, list]:
    """
    from_sector → to_sector 로 경계 Grid를 전부 이동.
    즉, boundary_pairs_info에서 (Sector=from_sector, neighbor_sector=to_sector)에 해당하는
    모든 Grid_ID를 찾아서, grid에서 해당 Grid의 Sector 값을 to_sector로 재할당.
    반환: (변경된 grid, 이동한 Grid_ID 목록)
    """
    target_boundary = boundary_pairs_info[
        (boundary_pairs_info["Sector"] == from_sector) &
        (boundary_pairs_info["neighbor_sector"] == to_sector)
    ]
    moved_ids = target_boundary["Grid_ID"].unique()
    if len(moved_ids) == 0:
        return grid, []
    grid.loc[grid["Grid_ID"].isin(moved_ids), "Sector"] = to_sector
    return grid, moved_ids



# -------------------------------
# 6. 전체 실행 흐름
# -------------------------------
# 먼저, boundary_pairs_info 생성 (grid는 앞서 생성한 grid 객체, Sector는 int로 통일되어 있다고 가정)
boundary_pairs_info = build_boundary_pairs_info(grid)

import geopandas as gpd
import pandas as pd
import matplotlib.pyplot as plt

# Assume required helper functions exist: build_boundary_pairs_info, recalc_sector_npps_sum, print_npps_diff

def give_bulk_boundaries_from_excess(grid: gpd.GeoDataFrame, sector_neighbors: dict, excess_sectors: list) -> tuple:
    """
    Excess NPPS sectors give all of their boundary grids to non-excess neighbors (bulk move),
    in the order of the fewest available neighbors first.
    Returns updated grid and list of all moved grid IDs.
    """
    boundary_pairs_info = build_boundary_pairs_info(grid)
    moved_all = []
    old_sum = recalc_sector_npps_sum(grid)

    eligible_donors = sorted(
        [s for s in excess_sectors],
        key=lambda s: len([n for n in sector_neighbors[s] if n not in excess_sectors])
    )

    for donor in eligible_donors:
        recipients = [n for n in sector_neighbors[donor] if n not in excess_sectors]
        print(f"\n🔁 Sector {donor} attempts to give boundary grids to: {recipients}")

        for recipient in recipients:
            old_local_sum = recalc_sector_npps_sum(grid)
            grid, moved_ids = take_boundary_from_neighbor(grid, boundary_pairs_info, donor, recipient)
            # Check if moved_ids is not empty instead of directly evaluating its truthiness.
            if len(moved_ids) > 0: # Check if the list is not empty.
                moved_all.extend(moved_ids)
                new_local_sum = recalc_sector_npps_sum(grid)
                print(f"✅ Moved {len(moved_ids)} grids from Sector {donor} ➝ {recipient}")
                print_npps_diff(old_local_sum, new_local_sum, [donor, recipient])

    # Final summary
    final_sum = recalc_sector_npps_sum(grid)
    print("\n📊 Final NPPS (partial):")
    print(final_sum.sort_values("Sector"))

    return grid, moved_all

def plot_moved_grids(grid: gpd.GeoDataFrame, moved_ids: list, beats: gpd.GeoDataFrame, title="Grid Transfers from Excess Sectors"):
    fig, ax = plt.subplots(figsize=(12, 8))
    grid.plot(ax=ax, facecolor="lightgray", edgecolor="black", linewidth=0.2)
    grid[grid["Grid_ID"].isin(moved_ids)].plot(
        ax=ax, facecolor="yellow", edgecolor="red", linewidth=1, label="Moved Grids"
    )
    beats.boundary.plot(ax=ax, color="black", linestyle="--", linewidth=1.5)
    ax.set_title(title)
    ax.legend()
    ax.set_axis_off()
    plt.show()

# Step 1: Define excess sectors and neighbors
excess_sectors = [4, 6, 7]
# Make sure your 'grid' and 'sector_neighbors' are already defined

# Step 2: Run the bulk transfer function
grid, moved_ids = give_bulk_boundaries_from_excess(grid, sector_neighbors, excess_sectors)

# Step 3: Visualize result
plot_moved_grids(grid, moved_ids, berkeley_beats, title="Grid Transfers from Excess Sectors")

# -------------------------------
# Final: Colored Sector Map (After Excess Redistribution)
# -------------------------------
import matplotlib.pyplot as plt
from matplotlib.patches import Patch

fig, ax = plt.subplots(figsize=(12, 8))

# 1) Sector 목록 추출 & 컬러맵 설정
unique_sectors = sorted(grid["Sector"].unique())
cmap = plt.cm.get_cmap("tab20", len(unique_sectors))
color_dict = {sec: cmap(i) for i, sec in enumerate(unique_sectors)}

# 2) Sector별로 Grid 색상 구분
for sec in unique_sectors:
    subset = grid[grid["Sector"] == sec]
    subset.plot(
        ax=ax,
        facecolor=color_dict[sec],
        edgecolor="black",
        linewidth=0.5,
        alpha=1,
        label=f"Sector {sec}"
    )

# 3) Patrol Sector(Shapefile) 경계 표시 (점선)
berkeley_beats.boundary.plot(
    ax=ax,
    color="black",
    linewidth=1.5,
    linestyle="--",
    label="Sector Boundaries"
)

# 4) 범례 (각 Sector 색상 + 점선 경계)
legend_patches = [
    Patch(facecolor=color_dict[sec], edgecolor="black", label=f"Sector {sec}")
    for sec in unique_sectors
]
sector_boundary_patch = Patch(facecolor="none", edgecolor="black", label="Sector Boundaries", linestyle="--")
legend_patches.append(sector_boundary_patch)

ax.legend(
    handles=legend_patches,
    title="Final Reassigned Grid by Sector",
    loc="upper left",
    bbox_to_anchor=(1.05, 1),
    borderaxespad=0.
)

ax.set_title("Final Sector Assignments After Boundary Reassignment", fontsize=14)
ax.set_axis_off()
plt.show()

def take_bulk_boundaries_to_deficient(grid: gpd.GeoDataFrame, deficient_sector: int, neighbors: list) -> tuple:
    boundary_pairs_info = build_boundary_pairs_info(grid)
    moved_all = []
    old_sum = recalc_sector_npps_sum(grid)

    print(f"\n🟢 Sector {deficient_sector} attempts to pull grids from neighbors: {neighbors}")

    for nbr in neighbors:
        old_local_sum = recalc_sector_npps_sum(grid)
        grid, moved_ids = take_boundary_from_neighbor(grid, boundary_pairs_info, nbr, deficient_sector)

        if len(moved_ids) > 0:
            moved_all.extend(moved_ids)
            new_local_sum = recalc_sector_npps_sum(grid)
            print(f"✅ Moved {len(moved_ids)} grids from Sector {nbr} ➝ {deficient_sector}")
            print_npps_diff(old_local_sum, new_local_sum, [nbr, deficient_sector])
        else:
            print(f"⚠️ No boundary grids moved from Sector {nbr} ➝ {deficient_sector} (already transferred or not adjacent)")

    final_sum = recalc_sector_npps_sum(grid)
    print("\n📊 Final NPPS (partial):")
    print(final_sum.sort_values("Sector"))

    return grid, moved_all

# 예시 실행
deficient_sector = 12
neighbors_12 = [3, 11, 13]  # 미리 정의된 이웃들

grid, moved_ids = take_bulk_boundaries_to_deficient(grid, deficient_sector, neighbors_12)

import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(12, 8))

# (A) 전체 Grid (배경)
grid.plot(
    ax=ax,
    facecolor="lightgray",
    edgecolor="black",
    linewidth=0.2,
    alpha=0.6
)

# (B) Sector 12로 이동된 Grid 강조 (노란색 + 빨간 테두리)
moved_grids = grid[grid["Grid_ID"].isin(moved_ids)]
moved_grids.plot(
    ax=ax,
    facecolor="yellow",
    edgecolor="red",
    linewidth=1.0,
    alpha=1.0,
    label="Moved to Sector 12"
)

# (C) Patrol Sector 공식 경계 (점선)
berkeley_beats.boundary.plot(
    ax=ax,
    color="black",
    linewidth=1.2,
    linestyle="--",
    label="Sector Boundaries"
)

# 범례 및 제목
ax.legend()
ax.set_title("Newly Assigned Grids to Sector 12 with Sector Boundaries", fontsize=14)
ax.set_axis_off()
plt.show()

from matplotlib.patches import Patch

fig, ax = plt.subplots(figsize=(12, 8))

# 1) 유니크 Sector 값 및 컬러맵 설정
unique_sectors = sorted(grid["Sector"].unique())
cmap = plt.cm.get_cmap("tab20", len(unique_sectors))
color_dict = {sec: cmap(i) for i, sec in enumerate(unique_sectors)}

# 2) 각 Sector에 색상 입혀서 시각화
for sec in unique_sectors:
    subset = grid[grid["Sector"] == sec]
    subset.plot(
        ax=ax,
        facecolor=color_dict[sec],
        edgecolor="black",
        linewidth=0.5,
        alpha=1.0,
        label=f"Sector {sec}"
    )

# 3) 공식 Sector 경계선
berkeley_beats.boundary.plot(
    ax=ax,
    color="black",
    linewidth=1.2,
    linestyle="--",
    label="Sector Boundaries"
)

ax.legend(
    handles=legend_patches,
    title="Final Reassigned Grid by Sector",
    loc="upper left",
    bbox_to_anchor=(1.05, 1),
    borderaxespad=0.
)

ax.set_title("Final Sector Assignments After Boundary Reassignment", fontsize=14)
ax.set_axis_off()
plt.show()

grid.to_file("final_grid.shp")
print("Final optimized grid saved as final_grid.shp")

import numpy as np

def evaluate_npps_balance(old_sum: pd.DataFrame, new_sum: pd.DataFrame):
    # Merge old and new NPPS data
    merged = old_sum.merge(new_sum, on="Sector", suffixes=("_old", "_new"))

    # Calculate Variance
    old_variance = np.var(merged["sector_total_npps_old"])
    # Access the correct column for new variance calculation: sector_total_npps_new
    new_variance = np.var(merged["sector_total_npps_new"])

    # Max/Min Ratio
    old_max_min_ratio = merged["sector_total_npps_old"].max() / merged["sector_total_npps_old"].min()
    # Access the correct column for new max/min ratio calculation: sector_total_npps_new
    new_max_min_ratio = merged["sector_total_npps_new"].max() / merged["sector_total_npps_new"].min()

    # Deviation from Mean (%)
    old_mean = merged["sector_total_npps_old"].mean()
    # Access the correct column for new mean calculation: sector_total_npps_new
    new_mean = merged["sector_total_npps_new"].mean()

    merged["old_dev_from_mean(%)"] = ((merged["sector_total_npps_old"] - old_mean) / old_mean) * 100
    merged["new_dev_from_mean(%)"] = ((merged["sector_total_npps_new"] - new_mean) / new_mean) * 100

    print("\n📊 **NPPS Variance Comparison** 📊")
    print(f"Before Optimization: {old_variance:.2f}")
    print(f"After Optimization:  {new_variance:.2f}")

    print("\n📊 **Max/Min Ratio Comparison** 📊")
    print(f"Before Optimization: {old_max_min_ratio:.2f}")
    print(f"After Optimization:  {new_max_min_ratio:.2f}")

    print("\n📊 **Deviation from Mean (%) (First 5 Sectors)** 📊")
    print(merged[["Sector", "old_dev_from_mean(%)", "new_dev_from_mean(%)"]].head(14))

    return merged  # 반환해서 시각화 등 추가 분석 가능

# Assuming sector_npps_sum and grid are already defined
evaluation_result = evaluate_npps_balance(sector_npps_sum, recalc_sector_npps_sum(grid))

def normalized_score(value, worst, best):
    score_0_to_1 = (worst - value) / (worst - best)  # The lower the value, the better
    score_0_to_1 = max(min(score_0_to_1, 1), 0)  # Clamp the result between 0 and 1
    return round(score_0_to_1 * 9 + 1, 1)  # Convert to a 1~10 scale

# Assumption: Worst/Best thresholds for Variance (based on past data or domain knowledge)
worst_variance = 120000
best_variance = 60000

# Worst/Best thresholds for Max/Min Ratio
worst_ratio = 2.0
best_ratio = 1.25

# Current values
before_variance = 105089.55
after_variance = 65383.51
before_ratio = 1.76
after_ratio = 1.54

# Calculate Scores
before_var_score = normalized_score(before_variance, worst_variance, best_variance)
after_var_score = normalized_score(after_variance, worst_variance, best_variance)

before_ratio_score = normalized_score(before_ratio, worst_ratio, best_ratio)
after_ratio_score = normalized_score(after_ratio, worst_ratio, best_ratio)

# Final Score is the average of variance score and ratio score
before_final_score = round((before_var_score + before_ratio_score) / 2, 1)
after_final_score = round((after_var_score + after_ratio_score) / 2, 1)

print(f"📊 **Workload Balance Score (Logic-Based)** 📊")
print(f"Before Optimization: {before_final_score}/10")
print(f"After Optimization:  {after_final_score}/10")

########################################
# 6) Sector별 NPPS 합계 & 시각화 (Polygon 단위)
########################################
sector_npps_sum = grid.groupby("Sector")["total_npps"].sum().reset_index()
sector_npps_sum.rename(columns={"total_npps": "sector_total_npps"}, inplace=True)

# berkeley_beats와 merge (둘 다 int형 Sector)
berkeley_beats = berkeley_beats.merge(sector_npps_sum, on="Sector", how="left")

print("\n📊 **Sector별 NPPS 총합** 📊\n")
print(berkeley_beats[["Sector", "sector_total_npps"]])

fig, ax = plt.subplots(figsize=(12, 8))
cmap = plt.cm.Reds
norm = mcolors.Normalize(vmin=berkeley_beats["sector_total_npps"].min(),
                         vmax=berkeley_beats["sector_total_npps"].max())

berkeley_beats.plot(column="sector_total_npps", cmap=cmap, norm=norm,
                    edgecolor="black", linewidth=1, alpha=0.7, ax=ax)

# Sector 중심점 라벨 표시
berkeley_beats["centroid"] = berkeley_beats.geometry.centroid
for idx, row in berkeley_beats.iterrows():
    ax.text(row["centroid"].x, row["centroid"].y,
            f"{int(row['Sector'])}",
            fontsize=10, color="black", ha="center", va="center", fontweight="bold")

sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)
sm.set_array([])
cbar = plt.colorbar(sm, ax=ax, fraction=0.03, pad=0.02)
cbar.set_label("Total WLS per Sector", fontsize=12)

ax.set_title("Sector-Level WLS Heatmap in Berkeley Police Patrol", fontsize=14)
ax.set_axis_off()
plt.show()

import geopandas as gpd
import matplotlib.pyplot as plt

# Load the final grid
grid = gpd.read_file("final_grid.shp")

# Create a figure
fig, ax = plt.subplots(figsize=(12, 8))

# Dissolve all grid cells by sector to get a single polygon per sector
sectors = grid.dissolve(by="Sector")

# Plot all sector boundaries in black
sectors.boundary.plot(
    ax=ax,
    color='black',
    linewidth=1.5,
    alpha=1.0
)

# Set title and turn off axis
ax.set_title("Berkeley Police Department Sectors", fontsize=14)
ax.set_axis_off()

# Show the plot
plt.tight_layout()
plt.show()

# Print basic information
print("\nSector Information:")
print(f"Number of sectors: {len(sectors)}")
print("\nSector IDs:")
print(sorted(sectors.index.tolist()))

import geopandas as gpd
import pandas as pd
import numpy as np
from shapely.ops import unary_union, nearest_points
from shapely.geometry import LineString, MultiLineString, Point, MultiPoint, Polygon, MultiPolygon
import os
import matplotlib.pyplot as plt
from shapely.geometry import shape, mapping
from shapely.ops import transform
from shapely.wkt import loads, dumps

def find_nearest_point_on_lines(point, lines, max_distance=50):
    """
    Find the nearest point on any line within max_distance meters.
    Returns None if no line is within max_distance.
    """
    min_dist = float('inf')
    nearest_point = None

    for line in lines:
        if line.distance(point) <= max_distance:
            p = line.interpolate(line.project(point))
            dist = point.distance(p)
            if dist < min_dist:
                min_dist = dist
                nearest_point = p

    return nearest_point if min_dist <= max_distance else None

def snap_polygon_to_streets(polygon, street_lines, tolerance=50):
    """
    Snap a single polygon's vertices to nearest street segments.
    """
    coords = list(polygon.exterior.coords)
    new_coords = []

    # Process each vertex
    for i, coord in enumerate(coords[:-1]):  # Skip last point (same as first)
        point = Point(coord)
        snapped = find_nearest_point_on_lines(point, street_lines, tolerance)

        if snapped:
            new_coords.append((snapped.x, snapped.y))
        else:
            new_coords.append(coord)

    # Close the polygon
    new_coords.append(new_coords[0])

    # Create new polygon
    return Polygon(new_coords)

def snap_to_streets(geom, streets, tolerance=50):
    """
    Snap polygon vertices to nearest street segments within tolerance distance.
    Handles both Polygon and MultiPolygon geometries.
    """
    # Extract all street geometries
    street_lines = [geom for geom in streets.geometry]

    if isinstance(geom, Polygon):
        return snap_polygon_to_streets(geom, street_lines, tolerance)
    elif isinstance(geom, MultiPolygon):
        # Handle each polygon in the MultiPolygon separately
        snapped_polys = []
        for poly in geom.geoms:
            snapped_poly = snap_polygon_to_streets(poly, street_lines, tolerance)
            snapped_polys.append(snapped_poly)
        return MultiPolygon(snapped_polys)
    else:
        raise ValueError(f"Unsupported geometry type: {type(geom)}")

def smooth_sectors(grid, streets, output_dir="output"):
    """
    Smooth sector boundaries by snapping to nearby streets and export as shapefile.

    Args:
        grid: GeoDataFrame containing the grid-based sectors
        streets: GeoDataFrame containing street centerlines
        output_dir: Directory to save output files
    """
    # Create output directory if it doesn't exist
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Ensure both datasets are in the same CRS
    streets = streets.to_crs(grid.crs)

    # Convert grid to polygons by sector
    sectors = []
    for sector in sorted(grid["Sector"].unique()):
        print(f"Processing Sector {sector}...")
        sector_grids = grid[grid["Sector"] == sector]
        # Dissolve all grid cells in the sector into a single polygon
        sector_polygon = unary_union(sector_grids.geometry)
        # Snap to streets
        snapped_polygon = snap_to_streets(sector_polygon, streets)
        sectors.append({
            "Sector": sector,
            "geometry": snapped_polygon
        })

    # Create GeoDataFrame of snapped sector polygons
    snapped_sectors = gpd.GeoDataFrame(sectors, crs=grid.crs)

    # Save the snapped sectors
    output_file = os.path.join(output_dir, "snapped_sectors.shp")
    snapped_sectors.to_file(output_file)

    print(f"Snapped sectors saved to {output_file}")
    return snapped_sectors

def visualize_comparison(original_grid, snapped_sectors, streets):
    """
    Create a visualization comparing original and snapped sectors with streets.
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))

    # Original sectors with streets
    original_sectors = original_grid.dissolve(by="Sector")
    streets.plot(ax=ax1, color='gray', linewidth=0.5, alpha=0.5)
    original_sectors.boundary.plot(ax=ax1, color='black', linewidth=1.5)
    ax1.set_title("Original Sector Boundaries")
    ax1.set_axis_off()

    # Snapped sectors with streets
    streets.plot(ax=ax2, color='gray', linewidth=0.5, alpha=0.5)
    snapped_sectors.boundary.plot(ax=ax2, color='black', linewidth=1.5)
    ax2.set_title("Snapped Sector Boundaries")
    ax2.set_axis_off()

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    # Load the final grid and centerlines data
    print("Loading data...")
    grid = gpd.read_file("final_grid.shp")
    streets = gpd.read_file("Centerlines.shp")

    # Run the snapping process
    print("Snapping sectors to streets...")
    snapped = smooth_sectors(grid, streets)

    # Visualize the comparison
    print("Generating visualization...")
    visualize_comparison(grid, snapped, streets)

import geopandas as gpd
import matplotlib.pyplot as plt

# shapefile 불러오기
shapefile_path = "output/snapped_sectors.shp"
gdf = gpd.read_file(shapefile_path)

# 데이터 확인
print(gdf.head())

# 시각화 - Sector별 색상
gdf.plot(column='Sector', cmap='tab20', legend=True, edgecolor='black')

plt.show()

